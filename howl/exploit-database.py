from elasticsearch import Elasticsearch
from multiprocessing import Pool
import argparse
es = Elasticsearch(hosts='127.0.0.1')
es.indices.create(index='vuldb', ignore=400)


def csv2es(vul):
    vul = vul.split(',')
    es.index(
        index='vuldb',
        doc_type='vulnerabilities',
        id='exploitdb-{}'.format(vul[0]),
        body={'title': vul[2].strip('"'),
              'time': vul[3],
              'reference':
              'https://www.exploit-db.com/exploits/{}/'.format(vul[0]),
              'source': 'exploit-db'})
    print(vul[2])


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='import vuls')
    parser.add_argument('-f', help='file', default='files.csv')
    args = parser.parse_args()
    p = Pool(10)
    with open(args.f, 'r') as vulf:
        for vul in vulf.readlines()[1:]:
            p.apply_async(csv2es, (vul,))
    p.close()
    p.join()